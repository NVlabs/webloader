{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Example of using WebLoader with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.optim\n",
    "from torchvision import models\n",
    "\n",
    "import webloader as wl\n",
    "\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "import torchtrainers as tt\n",
    "\n",
    "os.chdir(\"/tmp\")\n",
    "\n",
    "from webloader import tarrecords\n",
    "print(tarrecords.errors_are_fatal)\n",
    "tarrecords.errors_are_fatal = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.array([0.485, 0.456, 0.406], \"f\")\n",
    "std = np.array([0.229, 0.224, 0.225], \"f\")\n",
    "def norm_image(xs):\n",
    "    return (xs-mean[None,None,None,:])/std[None,None,None,:]\n",
    "def norm_cls(ys):\n",
    "    ys = ys.astype(np.int64)\n",
    "    return ys-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "494.27 samples/s 7.72 batches/s\n",
      "0 : Tensor torch.Size([64, 3, 224, 224]) cpu torch.float32 -2.1179039478302 2.640000104904175\n",
      "1 : Tensor torch.Size([64]) cpu torch.int64 0 957\n"
     ]
    }
   ],
   "source": [
    "training_urls = \"http://storage.googleapis.com/lpr-imagenet-augmented/imagenet_train-{0000..0147}-{000..019}.tgz\"\n",
    "training_size = 1000000\n",
    "training = wl.MultiWebLoader(\n",
    "    training_urls, training_size,\n",
    "    fields=\"ppm;png;jpg cls\",\n",
    "    batch_transforms=[norm_image, norm_cls],\n",
    "    batch_size=64,\n",
    "    converters=\"torch\",\n",
    "    shuffle=1000,\n",
    "    verbose=False,\n",
    "    use_torch_mp=True,\n",
    "    queue_size=200,\n",
    "    processes=4)\n",
    "wl.loader_test(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181.14 samples/s 2.83 batches/s\n",
      "0 : Tensor torch.Size([64, 3, 224, 224]) cpu torch.float32 -2.1179039478302 2.640000104904175\n",
      "1 : Tensor torch.Size([64]) cpu torch.int64 16 983\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(\"./imagenet_val-0000.tgz\"):\n",
    "    testing_urls = \"./imagenet_val-0000.tgz\"\n",
    "else:\n",
    "    testing_urls = \"http://storage.googleapis.com/lpr-imagenet-augmented/imagenet_val-0000-000.tgz\"\n",
    "testing_size = 50000\n",
    "testing = wl.WebLoader(\n",
    "    testing_urls, testing_size,\n",
    "    fields=\"ppm;png;jpg cls\",\n",
    "    batch_transforms=[norm_image, norm_cls],\n",
    "    batch_size=64,\n",
    "    epochs=1,\n",
    "    converters=\"torch\")\n",
    "wl.loader_test(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50()\n",
    "model = model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting optimizer: SGD ( Parameter Group 0 dampening: 0 lr: 0.001 momentum: 0 nesterov: False weight_decay: 0 )\n",
      "training    5056 /     5000 time 00:00:00 / 00:00:19 101% loss   7.05573 [    79] err   0.99875\n",
      "loss 7.0588 err 1.0000\n"
     ]
    }
   ],
   "source": [
    "reload(tt)\n",
    "#model = nn.DataParallel(model)\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "trainer = tt.Trainer(model=model,\n",
    "                     criterion=criterion,\n",
    "                     metrics=[tt.Misclassification],\n",
    "                     device=\"cuda\")\n",
    "trainer.set_lr(1e-3)\n",
    "trainer.fit_for(training, 5000)\n",
    "print(trainer.test_for(testing, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting optimizer: SGD ( Parameter Group 0 dampening: 0 lr: 0.01 momentum: 0 nesterov: False weight_decay: 0 )\n",
      "   0 test (none) ::: train  100% /00:00:37  loss 6.9733 err 0.9984       \n",
      "   1 test loss 7.1559 err 0.9990 ::: train  100% /00:00:37  loss 6.9449 err 0.9988       \n",
      "   2 test loss 7.0406 err 0.9971 ::: train  100% /00:00:37  loss 6.9353 err 0.9991       \n",
      "   3 test loss 7.0321 err 0.9980 ::: train  100% /00:00:37  loss 6.9189 err 0.9978       \n",
      "   4 test loss 6.9938 err 0.9980 ::: train  100% /00:00:37  loss 6.9250 err 0.9981       \n",
      "   5 test loss 6.9262 err 0.9941 ::: train  100% /00:00:37  loss 6.8977 err 0.9981       \n",
      "   6 test loss 6.9308 err 0.9971 ::: train  100% /00:00:37  loss 6.8868 err 0.9959       \n",
      "   7 test loss 6.9245 err 0.9990 ::: train  100% /00:00:37  loss 6.8584 err 0.9984       \n",
      "   8 test loss 6.8566 err 0.9971 ::: train  100% /00:00:37  loss 6.8452 err 0.9950       \n",
      "   9 test loss 6.8744 err 0.9961 ::: train  100% /00:00:37  loss 6.8300 err 0.9959       \n"
     ]
    }
   ],
   "source": [
    "tt.training(trainer, training, 10000, testing, 1000, epochs=10, learning_rates=[(0,1e-2), (300000, 1e-3)])\n",
    "\n",
    "#For full training, use appropriate epoch sizes for the dataset:\n",
    "#tt.training(trainer, training, 1000000, testing, 50000, epochs=100, learning_rates=[(0,1e-2), (300000, 1e-3)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
